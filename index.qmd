---
title: "Data Analytic Workflow (Introduction)"
author: "Emmanuel Adewuyi"
format: html
editor: visual
---

By the end of this session, you should be able to:

-   Load and inspect a dataset in R

-   Clean data and handle missing values

-   Create summary tables and visualizations

-   Ask and answer questions with EDA

-   Fit and interpret a simple predictive model

-   Evaluate model performance

-   Export results for reporting

## Load Necessary Packages

```{r}
required_pkgs <- c(
"tidyverse",
"palmerpenguins",
"skimr",
"janitor",
"gtsummary",
"broom",
"yardstick",
"DataExplorer"
)

to_install <- required_pkgs[!required_pkgs %in% installed.packages()[, "Package"]]
if (length(to_install) > 0) install.packages(to_install)

library(tidyverse)
library(palmerpenguins)
library(skimr)
library(janitor)
library(gtsummary)
library(broom)
library(yardstick)

```

## Load Dataset

We will be using the Penguin dataset obtainable from the `palmerpenguin` package

```{r}
data("penguins")
df <- penguins

glimpse(df)

```

### Data Dictionary

-   species: penguin species

-   island: island in Palmer Archipelago

-   bill_length_mm, bill_depth_mm: bill measurements

-   flipper_length_mm: flipper length

-   body_mass_g: body mass

-   sex: male/female

-   year: year of study

## First checks: shape, missingness, duplicates

```{r}
dim(df)
names(df)

df %>% summarise(across(everything(), ~sum(is.na(.))))
df %>% janitor::get_dupes() %>% head()
```

## Cleaning & preparation (Feature engineering)

It involves making the data fit enough for modelling.

Typical tasks:

-   Standardize column names

-   Handle missing values

-   Recode factors / fix inconsistent labels

-   Create derived variables

```{r}
df_clean <- df %>%
janitor::clean_names() %>%
mutate(
species = as.factor(species),
island  = as.factor(island),
sex     = as.factor(sex),
year    = as.factor(year),
body_mass_kg = body_mass_g / 1000
)

glimpse(df_clean)

```

### Handle missing data

Here we’ll drop rows missing key modelling variables (simple approach for teaching). Later you can discuss imputation.

```{r}
df_model <- df_clean %>%
drop_na(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, sex)

dim(df_model)
```

## EDA

```{r}
df_model %>% DataExplorer::plot_histogram()
```

### Quick overview using `skimr`

```{r}
skim(df_model)

```

**Some Analytic Questions**

1.  Ask analytic questions (examples)

2.  Do species differ in average body mass?

3.  Which predictors best explain body mass?

4.  Does sex matter after controlling for measurements?

### Summary Tables

#### Numerical Summaries

df_model %\>%

summarise(

n = n(),

mean_mass = mean(body_mass_g),

sd_mass = sd(body_mass_g),

min_mass = min(body_mass_g),

max_mass = max(body_mass_g)

)

```{r}
df_model %>%
summarise(
n = n(),
mean_mass = mean(body_mass_g),
sd_mass = sd(body_mass_g),
min_mass = min(body_mass_g),
max_mass = max(body_mass_g)
)

```

#### Group (Categorical) Summaries

```{r}
df_model %>%
group_by(species) %>%
summarise(
n = n(),
mean_mass = mean(body_mass_g),
sd_mass = sd(body_mass_g),
mean_flipper = mean(flipper_length_mm),
.groups = "drop"
) %>%
arrange(desc(mean_mass))
```

### Visuals

Distribution of the Body Mass

```{r}
ggplot(df_model, aes(x = body_mass_g)) +
geom_histogram(bins = 30) +
labs(title = "Distribution of Body Mass", x = "Body mass (g)", y = "Count")+ facet_grid(~species)

```

Body Mass by Species

```{r}
ggplot(df_model, aes(x = species, y = body_mass_g)) +
geom_violin() +
labs(title = "Body Mass by Species", x = "Species", y = "Body mass (g)")

```

Relationships

```{r}
ggplot(df_model, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +
geom_point(alpha = 0.7) +
geom_smooth(method = "lm", se = FALSE) +
labs(
title = "Body Mass vs Flipper Length",
x = "Flipper length (mm)",
y = "Body mass (g)"
)

```

# ============================================================

# ML classification on palmerpenguins using tidymodels

# Predict species from morphology (bill/ﬂipper/body mass) + sex/island/year

# ============================================================

# Packages

```{r}
library(tidymodels)
library(palmerpenguins)
library(tidyverse)
tidymodels_prefer()
set.seed(123)
```

# ---------------------------

# 1) Data

# ---------------------------

```{r}
# Load dataset
data("penguins", package = "palmerpenguins") 

# Clean dataset
peng <- penguins %>%
  dplyr::select(species, island, bill_length_mm, bill_depth_mm,
                flipper_length_mm, body_mass_g, sex, year) %>%
  drop_na(species, island, bill_length_mm, bill_depth_mm,
          flipper_length_mm, body_mass_g, sex, year) %>%
  mutate(
    species = factor(species),
    island  = factor(island),
    sex     = factor(sex),
    year    = factor(year)  # categorical; numeric if needed
  )
```

# ---------------------------

# 2) Split + CV folds

# ---------------------------

```{r}
split <- initial_split(peng, prop = 0.80, strata = species)
train <- training(split)
test  <- testing(split)

folds <- vfold_cv(train, v = 5, strata = species)
```

# ---------------------------

# 3) Recipe (preprocessing)

# ---------------------------

```{r}
rec <- recipe(species ~ ., data = train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_numeric_predictors())
```

# ---------------------------

# 4) Model specs

# ---------------------------

# (A) Multinomial logistic regression (glmnet)

```{r}
log_spec <- multinom_reg(mode = "classification",
                         penalty = tune(), mixture = tune()) %>%
  set_engine("glmnet")
```

# (B) Random forest

```{r}
rf_spec <- rand_forest(
  mode  = "classification",
  trees = 1000,
  mtry  = tune(),
  min_n = tune()
) %>%
  set_engine("ranger", importance = "impurity")

```

# Workflows

```{r}
log_wf <- workflow() %>% add_recipe(rec) %>% add_model(log_spec)
rf_wf  <- workflow() %>% add_recipe(rec) %>% add_model(rf_spec)
```

# ---------------------------

# 5) Tuning grids

# ---------------------------

# Grid for glmnet

```{r}
log_grid <- grid_regular(
  penalty(range = c(-4, 0)),  # 10^-4 to 10^0
  mixture(range = c(0, 1)),
  levels = c(20, 6)
)
```

# Grid for RF (mtry finalized after recipe is prepped)

```{r}

rf_grid <- grid_space_filling(
  mtry(range = c(2L, 9)),
  min_n(range = c(5L, 20L)),
  size = 25
)



```

# Metrics

```{r}
cls_metrics <- metric_set(accuracy, kap, mn_log_loss, roc_auc)
```

# ---------------------------

# 6) Tune with CV

# ---------------------------

```{r}
log_res <- tune_grid(
  log_wf,
  resamples = folds,
  grid      = log_grid,
  metrics   = cls_metrics,
  control   = control_grid(save_pred = TRUE)
)
```

```{r}
rf_res <- tune_grid(
  rf_wf,
  resamples = folds,
  grid      = rf_grid,
  metrics   = cls_metrics,
  control   = control_grid(save_pred = TRUE)
)
```

# Compare (pick by accuracy; you can use log_loss too)

```{r}
collect_metrics(log_res) %>% arrange(desc(mean)) %>% print(n = 10)
collect_metrics(rf_res)  %>% arrange(desc(mean)) %>% print(n = 10)

best_log <- select_best(log_res, metric = "accuracy")
best_rf  <- select_best(rf_res,  metric = "accuracy")

best_log
best_rf
```

# ---------------------------

# 7) Finalize + fit on train, evaluate on test

# ---------------------------

```{r}
final_log_wf <- finalize_workflow(log_wf, best_log)
final_rf_wf  <- finalize_workflow(rf_wf,  best_rf)

final_log_fit <- last_fit(final_log_wf, split = split, metrics = cls_metrics)
final_rf_fit  <- last_fit(final_rf_wf,  split = split, metrics = cls_metrics)
```

# Test metrics

```{r}
collect_metrics(final_log_fit)
collect_metrics(final_rf_fit)

```

# Confusion matrix on test (for RF; repeat for LOG if you want)

```{r}
log_test_preds <- collect_predictions(final_log_fit)
log_test_preds %>%conf_mat(truth = species, estimate = .pred_class)

rf_test_preds <- collect_predictions(final_rf_fit)
rf_test_preds %>%
  conf_mat(truth = species, estimate = .pred_class)

rf_test_preds %>%
  accuracy(truth = species, estimate = .pred_class)
```

# ---------------------------

# 8) Fit the best model on ALL training data and save

# ---------------------------

# Choose winner based on test accuracy

```{r}
log_acc <- collect_metrics(final_log_fit) %>% filter(.metric == "accuracy") %>% pull(.estimate)
rf_acc  <- collect_metrics(final_rf_fit)  %>% filter(.metric == "accuracy") %>% pull(.estimate)

winner <- ifelse(rf_acc >= log_acc, "rf", "log")
winner

final_wf <- if (winner == "rf") final_rf_wf else final_log_wf

final_model_fit <- fit(final_wf, data = train)
```

# Save workflow (includes preprocessing + model)

```{r}
saveRDS(final_model_fit, file = "penguins_tidymodels_workflow.rds")
```

# ---------------------------

# 9) Predict on new data / test set

# ---------------------------

```{r}
test_class <- predict(final_model_fit, new_data = test, type = "class")
test_prob  <- predict(final_model_fit, new_data = test, type = "prob")

pred_out <- bind_cols(
  test %>% select(species),
  test_class,
  test_prob
)

head(pred_out)
```

# Optional: variable importance (RF only)

```{r}
if (winner == "rf") {
  final_model_fit %>%
    extract_fit_parsnip() %>%
    vip::vip(num_features = 15)
}
```

# Data Story telling and Visualisation

## 1. What is Storytelling with Data?

**Storytelling** means using data to communicate a message clearly — not just showing charts.

A good data story has:

-   **Context** – What problem are we exploring?
-   **Characters** – Who is affected? (patients, communities, programs)
-   **Conflict** – What challenge exists?
-   **Insight** – What patterns do we see?
-   **Action** – What should be done?

> *Data storytelling = Data + Visuals + Meaning + Action*

------------------------------------------------------------------------

## 2. What is Data Visualization?

**Data visualization** is the graphical representation of data to:

-   simplify complex information\
-   highlight patterns and trends\
-   support better decisions

Examples include bar charts, histograms, boxplots, and scatter plots.

> Visualization is powerful because the human brain understands images faster than tables.

------------------------------------------------------------------------

## 3. Why Does It Matter (Especially in Health)?

-   Helps health workers **see risks and trends**
-   Supports **policy decisions**
-   Makes research **understandable to non-experts**
-   Encourages **evidence-based actions**

------------------------------------------------------------------------

## 4. Load Packages & Dataset (Health Example)

We’ll use the `birthwt` dataset from the **MASS** package — it explores risk factors for **low birth weight**.

```{r}
library(MASS)
library(dplyr)
library(ggplot2)

data("birthwt")

head(birthwt)

```

## Understand the data

The birthwt data frame has 189 rows and 10 columns. The data were collected at Baystate Medical Center, Springfield, Mass during 1986.

-   low: indicator of birth weight less than 2.5 kg.

-   age: mother's age in years.

-   lwt: mother's weight in pounds at last menstrual period.

-   race: mother's race (1 = white, 2 = black, 3 = other).

-   smoke: smoking status during pregnancy.

-   ptl: number of previous premature labours.

-   ht: history of hypertension.

-   ui: presence of uterine irritability.

-   ftv: number of physician visits during the first trimester.

-   bwt: birth weight in grams.

```{r}
birthwt |>
summary()
```

### Wrangle some variable in the dataset

```{r}
birthwt |> 
  mutate(race=factor(race, levels=c(1,2,3), labels=c("White", "Black", "Others")),
         bwt=bwt/1000,
         ui=ifelse(ui==1, "Yes", "No"),
         ht=ifelse(ht==1, "Yes", "No")) -> newdf
```

```{r}
head(newdf)

```

## Start the Story: Our Question

*Does smoking increase the risk of low birth weight?*

```{r}
birthwt <- birthwt |>
mutate(
smoke = factor(smoke, labels = c("Non-smoker", "Smoker")),
low_bw = ifelse(bwt < 2500, "Low Birth Weight", "Normal")
)

```

## Distribution of Birthweight

```{r}
ggplot(birthwt, aes(bwt)) +
geom_histogram(bins=25) +
labs(
title = "Distribution of Birth Weight",
x = "Birth Weight (grams)",
y = "Count"
)

```

### Smoking vs Birthweight

```{r}
ggplot(birthwt, aes(x = smoke, y = bwt)) +
geom_boxplot() +
labs(
title = "Birth Weight by Smoking Status",
x = "Smoking Status",
y = "Birth Weight (grams)"
)

```

Risk of Low Birthweight by smoking

```{r}
birthwt |>
count(smoke, low_bw)
```

```{r}
birthwt |>
count(smoke, low_bw) |>
mutate(p = n / sum(n)) |>
ggplot(aes(smoke, p, fill = low_bw)) +
geom_col(position = "fill") +
labs(
title = "Proportion of Low Birth Weight by Smoking",
x = "Smoking Status",
y = "Proportion"
)

```

### Others

*Does mother's race affect the risk of low birth weight?*

```{r}
newdf2 <- newdf |>
mutate(
smoke = factor(smoke, labels = c("Non-smoker", "Smoker")),
low_bw = ifelse(bwt < 2500, "Low Birth Weight", "Normal")
)

```

### Mother's race vs Birthweight

```{r}
ggplot(newdf, aes(x = race, y = bwt)) +
geom_boxplot() +
labs(
title = "Birth Weight by Mother's race",
x = "Mother's race",
y = "Birth Weight (grams)"
)

```

Risk of Low Birthweight by Race

```{r}
birthwt |>
count(race, low_bw) |>
mutate(p = n / sum(n)) |>
ggplot(aes(race, p, fill = low_bw)) +
geom_col(position = "fill") +
labs(
title = "Proportion of Low Birth Weight by Race",
x = "Mother's race",
y = "Proportion"
)

```

The answer to the questions are evident from the visualisations.

It is easier for even a layman to answer the research questions.

# CRISP-DM, Data Mining methodology

CRISP-DM stands for Cross-Industry Standard Process for Data Mining. It’s a widely adopted framework that outlines the steps involved in a data analytics or data science project. Its primary purpose is to provide a systematic approach, ensuring that projects are well-defined, managed, and deliver valuable results. By adhering to a structured methodology, organizations can improve the efficiency and effectiveness of their data science initiatives, reducing the risk of costly errors and ensuring alignment with business objectives.

![CRISP-DM Image](index_files/figure-html/images.png){width="407"}
